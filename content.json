{"pages":[],"posts":[{"title":"Nvidia, Cuda 安裝","text":"update at 2020 2/26 by JasonLuotest on Ubuntu 16.04install Nvidia Driver 440.59, Cuda 10.1, Cudnn 7.6.5compatible with tensorflow-gpu 2.1 因為deep learning的套件更新速度很快，有時更新DL套件後相對應的cuda, nvidia driver也需要重新安裝，因此在這邊紀錄一下如何install, uninstall這些東西 Nvidia Driver安裝之前 首先，檢查顯卡是否可用lspci -nnk | grep -i nvidia，應出現下面這些 1234567801:00.0 VGA compatible controller [0300]: NVIDIA Corporation Device [10de:1b82] (rev a1) Kernel driver in use: nvidia Kernel modules: nvidiafb, nouveau, nvidia_drm, nvidia01:00.1 Audio device [0403]: NVIDIA Corporation Device [10de:10f0] (rev a1)02:00.0 VGA compatible controller [0300]: NVIDIA Corporation Device [10de:1b82] (rev a1) Kernel driver in use: nvidia Kernel modules: nvidiafb, nouveau, nvidia_drm, nvidia02:00.1 Audio device [0403]: NVIDIA Corporation Device [10de:10f0] (rev a1) 檢查是否已有安裝driver，可使用nvidia-smi或是dpkg -l ‘nvidia*’檢查 nvidia-smi除了可以檢查是否有安裝，同時也可以看到一些資訊(使用數據量，driver版本等) dpkg -l nvidia* 下載Nvidia Driver，到官網下載 解安裝Nvidia Driver 解除安裝之前先進入command prompt然後stop running Graphics session (此步驟可省略) 按下 [Ctrl]+[Alt]+[F1~F6] 然後登入作業系統 關閉Graphics Session sudo service lightdm stop (For Ubuntu) 卸載Nvidia Driver，下面三個步驟選其中一個 sudo apt-get purge nvidia* sudo /usr/bin/nvidia-uninstall sudo NVIDIA-Linux-x86_64-418.43.run –uninstall 重新開機 reboot 安裝Nvidia Driver 安裝之前先進入command prompt然後stop running Graphics session 按下 [Ctrl]+[Alt]+[F1~F6] 然後登入作業系統 關閉Graphics Session sudo service lightdm stop (For Ubuntu) 安裝Nvidia Driver sudo chmod +x NVIDIA-Linux-x86_64-XXX.run (在官網下載的檔案) sudo NVIDIA-Linux-x86_64-XXX.run 重新啟動電腦 reboot 確認套件是否已經安裝 dpkg -l nvidia* nvidia-smi Cuda安裝之前 如何確認電腦上的Cuda版本 cat /usr/local/cuda/version.txt nvcc -V 下載cuda，到官網下載cuda 10.1，選哪種下載都可以，我這邊是選擇runfile(local) or 用wget移除Cuda 移除舊版cuda，下面選一種(確保沒有/usr/local/cuda-XX.X資料夾) sudo apt-get --purge remove 'cuda*' sudo apt-get autoremove --purge cuda sudo /usr/local/cuda-10.2/bin/cuda-uninstaller 官網上寫的，cuda-10.2換成自己的版本 安裝Cuda 開始安裝Cuda (記得先用chmod +x讓檔案可以執行，前面兩種不適用跑_linux檔的) sudo ./cuda_10.1.105_418.39_linux.run --driver --silent sudo ./cuda_10.1.105_418.39_linux.run --toolkit --silent sudo ./cuda_10.1.105_418.39_linux.run --samples --silent 注意！！ 如果/tmp資料夾容量不夠時會不能安裝，需要給tmpdir=[YourDirectory]的參數，這邊我是給/home/tmp，所以上面的command會變成，同時/home/tmp要是chmod 777: sudo ./cuda_10.1.105_418.39_linux.run --driver --silent --tmpdir=/home/tmp sudo ./cuda_10.1.105_418.39_linux.run --toolkit --silent --tmpdir=/home/tmp sudo ./cuda_10.1.105_418.39_linux.run --samples --silent --tmpdir=/home/tmp 安裝時若出現Missing recommended library:libGLU.so，則進行下面命令: sudo apt-get install libglu1-mesa libxi-dev libxmu-dev libglu1-mesa-dev 安裝Cuda之後，需要將cuda路徑加入 ~/.bashrc 當中: 12export PATH=/usr/local/cuda/bin:$PATHexport LD_LIBRARY_PATH=/usr/local/cuda/64:$LD_LIBRARY_PATH 然後，source ~/.bashrc 使用nvcc -V檢查是否安裝成功 Cudnn (可以加速的套件)安裝之前 檢查主機上是否有cudnn及版本多少 cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2 從官網下載Cudnn，要下載CuDNN需要登錄，登錄後找尋與已安裝好的cuda版本相容的CuDNN(e.g. cuDNN v7.3.1 Library for Linux) tensorflow2.0需要v7.6以上的版本 刪除Cudnn 刪除相關檔案，通常會在/usr/local/cuda/include/和/usr/local/cuda/lib64/資料夾中 sudo rm -f /usr/local/cuda/include/*cudnn* sudo rm -f /usr/local/cuda/lib64/*cudnn* 安裝cudnn 下載之後進行解打包、壓縮 tar -xvf cudnn-10.1-linux-x64-v7.6.5.32.tgz 解完打包壓縮之後可以發現有個cuda的文件夾，裡面會有 cuda/include cuda/lib64 cuda/NVIDIA_SLA_cuDNN_Support.txt 複製檔案到cuda資料夾中 sudo cp cuda/include/cudnn.h /usr/local/cuda/include/ sudo cp cuda/lib64/lib* /usr/local/cuda/lib64/ 檢測Cudnn - 到cudnn_samples_v7檢測 TensorRT (optional) 跟libnvinfer.so.6, libnvinfer_plugin.so.6的檔案有關 安裝 下載TensorRT，同樣也需要先登錄才能下載 下載tar文件，並選擇相對應的系統 解壓縮tar.gz檔案 tar xzvf TensorRT-XXXXXXXXXXXXXX.tar 將路徑加入LD_LIBRARY_PATH export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/root/TC184610137/TensorRT-4.0.2.6/lib 安裝TensorRT, uff, raphsurgeon 12cd TensorRT-XXXX/pythonsudo pip install tensorrt-6.0.1.5-cp36-none-linux_x86_64.whl 123## install uffcd TensorRT-XXXX/uffpip install uff-0.6.5-py2.py3-none-any.whl 123## install graphsurgeoncd TensorRT-XXXX/graphsurgeonpip install graphsurgeon-0.4.1-py2.py3-none-any.whl 測試: 12import tensorrt as trtimport uff as uff Ref: Uninstall nvidia driver 檢查gpu驅動程式是否安裝 當/tmp資料夾容量不夠時 安裝步驟 TensorRT","link":"/2020/06/07/cuda-install/"},{"title":"deep-intro","text":"淺談正夯的深度學習前言&emsp;在2016年3月8日到15日期間，全世界的電腦科學家們甚至是全世界的人們都高度關注的一場世界棋賽，但與之前不同的是，這場世界棋賽並不是一般人與人之間的博奕，而是一場人與機器的世紀大對決。隨著AlphaGO降臨於眾人面前並以4:1戰勝人類最頂尖的棋手之一，開啟了大眾與企業對於人工智慧的熱情，也因此引發了一波人工智慧的熱潮。而在往後的日子中，到處都可以聽到深度學習的技術又在某一個領域得到重大的突破，但深度學習這個看似很新潮又很酷的東西是什麼玩意呢？它到底又厲害在哪裡呢？為什麼能夠短時間席捲好多領域？ what is deep learning ? &emsp;其實如果對這名詞有些好奇的人，去網路上google深度學習的圖片將會查到大量類似如上的圖片，圖片中可以看到一堆圈圈，而這些圈圈之間由很多的線所連接。可能看完上圖大家還是會覺得一頭霧水不知道這個東西到底是什麼，但如果將下圖擺在一起看時就會發現上圖和人類的神經網路有些相似。 &emsp;對！沒錯，深度學習某一程度其實模仿了人類身體中的神經網絡，圖中的一個一個圈圈代表了一個個神經元，而線則代表了神經元和神經元之間的連接(類似神經中的突觸)。此外，從圖中可以看到這些圈圈有分層，黃色的圈圈為輸入層(Input layer)，中間許多的藍&gt;色圈圈被稱為隱藏層(hidden layer)，最後的紅色圈圈則為輸出層(output layer)，這樣一個架構是現在最基本的深度學習模型。然而，這個模仿人體神經網絡的領域早在1950、1960年代就已經出現，當時這方面相關的研究也被學術界稱為『類神經網路』(Artificial neural network)，在1954年時，弗蘭克羅森布拉特(Frank Rosenblatt)提出『感知機』(Perceptron)的概念，而現在某些書上也可以看到多層感知機(Multi-Layer Perceptron，MLP)其實講的就是同一件事(Dnn)，所以深度學習並不像很多人所想像那樣突然橫空出世，而是已經&gt;經過很多時間的醞釀，蟄伏了很長一段時間。 怎麼以前沒有 現在有&emsp;看到這邊大家一定會想問，既然這些概念、演算法很早就已經出現了，為什麼現在才整個蹦出來出現在大家眼前？其實深度學習能夠發展起來都要歸因於互聯網、大數據以及現今電腦強大的運算能力。首先，這些網路要給眾人使用以前要先經過大量的訓練，而這些訓練過程中最不可或缺的即是品質良好的數據資料。舉最基本的手寫數字(Mnist)辨識來說，&gt;要讓這些機器能夠分辨照片中的數字到底是多少，我們要先讓機器看過許多不一樣的照片並且跟它說照片中的數字到底是多少，這個過程蠻像人類小時候的學習過程。&emsp;還記得我年代久遠的小時候，爸爸媽媽會給我很多卡片，像是某張卡片上面畫了一顆蘋果，然後卡片下面就會寫”蘋果”這兩個字。人們透過這樣幾張的字卡似乎就能很快學會蘋果這個東西，下次看到的時候雖然可能跟字卡上的蘋果有些差異，但是往往能正確的指出那個就是一顆蘋果。 &emsp;但是如果是利用深度學習的技術時只透過一丁點的資料是沒辦法辨別出巫婆手上的那 顆蘋果的，其實這也是深度學習遇到的問題，在訓練的時候必須有海量資料的幫忙，網路才 能夠訓練的很好，也因此在早期難以收集資料集的情況下，類神經網路的技術是很難勝過其 他傳統的機器學習演算法的。所幸互聯網以及處理大數據的技術的出現，人們在收集資料上 變得比以前簡單很多。下圖為2009年到2020年IDC預測的數位資料量，可以看到資料的成長>是非常的劇烈，幾乎是以指數的方式成長，因此，在未來不會沒有資料可以進行訓練，問題 只會變得要不要花時間去收集並管理資料而已。 &emsp;除了在訓練時需要龐大的資料外，電腦的運算能力在早期也是一大難題。在以前只有CPU的時代，只要把網路加深幾層或是神經元數加大，就會增加大量的訓練時間，因此要訓&gt;練一個複雜的神經網路往往需要數天、數個禮拜甚至數年。然而，隨著GPU、TPU、叢集(cluster)的出現，大大提昇了電腦的平行運算能力，人們不再像以往需要花大量時間訓練簡單&gt;的網路，同時訓練一個非常複雜的網路也變得較為容易，現在的深度學習研究者如果沒有GPU的話根本不用玩。如果你問我說GPU和CPU的差別在哪，那我會推薦你去看youtube上一個我覺得有趣又短的影片。 學習方法(機器學習)&emsp;一般機器學習領域中大致上可以概括成三類學習方式-監督式學習(Supervised learning)、非監督式學習(Unsupervised learning)、強化學習(Reinforcement learning)，還有一種是介於這監督與非監督之間的半監督式學習(semi-supervised learning)，在這邊就討論最前面兩種學習方式。 監督式學習&emsp;所謂監督式學習就是機器在學習的過程中有正確答案(label data)可以對照。舉例來說，就是大人帶小孩到動物園玩時，大人常常會指著動物跟孩子說這是甚麼樣的動物，小孩子從他看到的這些動物的特徵(feature)中學會辨別動物們，像是看到灰色、很大隻、&gt;長鼻子、大耳朵的就知道會是一隻大象，而有很長的脖子的通常就知道是長頸鹿。同樣的，機器也是這樣藉由反覆看到資料以及答案，從中尋找資料中的一些特徵，進而學會有甚麼樣特徵的資料會得到甚麼樣的答案。然而，在看似和人同樣的學習方式之下，機器所學到的東西往往會和人們學習到的會有所差異，機器常學到一些奇怪的東西導致在判斷的時候會判斷出一些非常奇怪的結果，有興趣的人可以看看以下的影片。 非監督式學習&emsp;接下來，非監督式學習其實就是在訓練過程中訓練資料沒有答案(No label)，在這個情況下，通常都是使用分群的方法將資料進行分類，常見的有k-means、DBSCAN、Hierarchical clustering等等，有一個不錯的網站，它將DBSCAN演算法做視覺化的呈現有興趣的可以到這個&gt;網站去看看。&emsp;除了上述說的分群方法之外，近幾年在非監督式學習中出現了一個非常熱門的技術叫做GAN (Generative Adversarial Networks)，最早由Ian Goodfellow在2014年提&gt;出，這個技術提出後受到大眾的關注，陸續幾年出現了一堆GAN的變形，Cycle GAN、WGAN、BEGAN、DRAGAN(我第一次看看成恐龍XD)……以下是摘自gan-zoo的圖，這圖統計了這幾年來與GAN相關的論文數量，可以看到2017~2018年與GAN相關的論文數量成長非常驚人。 深度學習三巨頭之一 Yann LeCun也對GAN的出現讚譽有加。 &emsp;現在網路上有很多畫風轉移的技術很多就有應用到GAN的技術，利用GAN的技術可以輕鬆的把一個照片轉移成梵谷的畫風，或是把一般的馬轉變成斑馬，甚至之前在Reddit上出現deepfakes的用戶使用GAN的技術將A片女主角的臉重新換成好萊屋女星的臉，這些噱頭十足&gt;的用途都大大提升了GAN的知名度。 強化學習&emsp;所謂的強化學習，指的是讓機器(Agent)與一個虛擬的環境(Environment)互動，機器因為環境的狀態而選擇採取某一種行動，而機器會因為這個行動獲得一個分數(Reward)，這個分數有可能是正或是負的，同時環境會因為機器採取的行動而改變，環境改變之後機器要重新看這個環境之後再根據環境狀態採取行動…一直循環，而在這些輪迴中機器要想辦法&gt;使獲得的分數(Reward)越高越好。下面這張圖就是強化學習機器與環境互動的圖。 &emsp;上述的過程很像是打遊戲的過程，也因此強化學習常常被用來讓機器學習玩遊戲或是下棋，最有名的例子就是AlphaGO了，下面是一段使用強化學習中的Q-learning的技術讓機&gt;器能夠自己玩打磚塊，從影片中可以看到剛開始，機器就像一個笨蛋一樣，但是過了120分&gt;鐘的訓練之後，機器玩起打磚塊就像一個專家一樣厲害XD 結語&emsp;這篇文章非常簡單的介紹了深度學習的背景以及機器學習的方法，但其實還有非常非常多的東西值得拿出來與大家討論，像是梯度下降、反向傳播、CNN、RNN、seq2seq……，以及這項技術如何被廣泛應用在各個領域之中。像是深度學習往往會與另一個領域結&gt;合，像是如果要把聊天機器人的好的話就要對語言學有一些認識，或是想把深度學習應用在文本搜尋系統可能就要對詞向量、tf-idf等要有所了解。如果對這些東西非常有興趣的其實網路上有很多的文章可以看，希望大家能夠在挖掘這些資料海時，能在過程中獲得許多成就感以及快樂～～ 最後推薦大家入坑方向XDD&emsp;如果對深度學習的歷史、演進或是想了解人工智慧到底會不會毀滅人類的話，推薦大家可以去翻翻李開復寫的人工智慧來了，而如果是想了解到底深度學習是怎樣架構的話推薦大家去找李弘毅教授的影片來看看，那對機器學習中的數學有興趣的話則是可以看田神在coursera上開的課程。 參考資料 &lt;人工智慧來了&gt; 李開復 李弘毅教授講義 GAN-ZOO IDC: The premier global market intelligence firm","link":"/2020/05/31/deep-intro/"},{"title":"dual_system","text":"灌雙系統(win10 + ubuntu 16.04.3 LTS)&emsp;有時候需要linux Terminal帶來的便利性，像是linux作業系統上開發軟體或寫程式&gt;比較便利，而windows上有好用的Microsoft軟體以及打電動，因此當電腦配備允許的話會想灌雙系統玩玩看。其實想要讓電腦上有linux系統除了灌雙系統外，也可以使用虛擬機(像是virtual box)或是Wubi，但是virtual box的話雖然安裝簡單且虛擬機裡安裝或移除系統並&gt;不會影響本身的系統，使得虛擬機較易適合初學者，但是在執行linux的時候速度會偏慢，&gt;而且打開時會占用較多系統資源。 以下是些簡單的優缺點整理：虛擬機安裝(virtual box等)： 優點：安全簡單、快速復原，適合初學者 缺點：電腦配備不夠好時，使用虛擬機速度會略慢","link":"/2020/05/31/dual-system/"}],"tags":[{"name":"tech","slug":"tech","link":"/tags/tech/"},{"name":"tensorflow","slug":"tensorflow","link":"/tags/tensorflow/"},{"name":"DeepLearning","slug":"DeepLearning","link":"/tags/DeepLearning/"},{"name":"system","slug":"system","link":"/tags/system/"}],"categories":[{"name":"AI","slug":"AI","link":"/categories/AI/"},{"name":"Computer System","slug":"Computer-System","link":"/categories/Computer-System/"}]}